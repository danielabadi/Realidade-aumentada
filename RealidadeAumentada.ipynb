{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trapalho Prático 2: Realidade Aumentada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nome: Pedro Geovanni Barbosa Ribeiro\n",
    "### Matrícula: 2018054478"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from OpenGL.GL import *\n",
    "from OpenGL.GLUT import *\n",
    "from OpenGL.GLU import *\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from objloader import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibração da câmera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados obtidos após a calibração no Octave\n",
    "\n",
    "Calibration results after optimization (with uncertainties):\n",
    "\n",
    "Focal Length:          fc = [ 409.92990   407.51958 ] +/- [ 15.80234   14.92167 ]\n",
    "\n",
    "Principal point:       cc = [ 305.07598   223.87874 ] +/- [ 7.35134   13.69615 ]\n",
    "\n",
    "Skew:             alpha_c = [ 0.00000 ] +/- [ 0.00000  ]   => angle of pixel axes = 90.00000 +\n",
    "/- 0.00000 degrees\n",
    "\n",
    "Distortion:            kc = [ 0.08372   -0.15473   -0.00711   -0.01103  0.00000 ] +/- [ 0.0759\n",
    "4   0.61318   0.00826   0.00684  0.00000 ]\n",
    "\n",
    "Pixel error:          err = [ 0.16554   0.21081 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecção de Alvos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções implementadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fun video_loader(num_frames = 0)\n",
    "\n",
    "Essa função é responsável por carregar o vídeo que foi recebido junto com a documentação do trabalho e separá-lo em diferentes frames, para serem utilizados em etapas posteriores. Para realizar estas funções o método VideoCapture do opencv foi utilizado, em seguida utilizamos o método read() para pegar cada frame separadamente. Nessa função também se permite decidir quantos frames se deseja, para facilitar os testes executados durante o desenvolvimento do trabalho.\n",
    "\n",
    "#### Fun image_pre_processing(images, bin_ts = 128)\n",
    "\n",
    "Esta função é responsável por realizar o pré-processamento da imagem, para que ela possa futuramente passar pelo processo de detecção de bordas. Nesta função primeiros realizamos a conversão da imagem da escala RGB para a escala cinza atráves da função\n",
    "cvtColor do opencv, em seguida realizamos o processo de binarização de imagem para facilitar a detecção de bordas, a binarização foi realizada atráves da função threshold do opencv. Nessa função podemos definir um limiar para a binarização, atráves de testes realizados dois valores de limiares foram satisfatórios 100 e 120, porém como apenas um limiar é permitido foi escolhido trabalhar com um limiar de 100. \n",
    "\n",
    "#### Fun edge_detection(image, low_ts = 100, max_ts = 200, show = False)\n",
    "\n",
    "Aqui temos a função responsável por realizar a detecção de bordas, nela receberemos uma imagem já pré-processada pela função anterior e apenas executaremos a função Canny do opencv, para obter as bordas, para passarmos como parâmetro para função caany utilizamos os limiraes 100 e 200, que são os limiares padrões e funcionaram bem. Na função implementada também permitimos que, se desejado, possamos plotar as bordas detectadas.\n",
    "\n",
    "#### Fun find_contours(edges)\n",
    "\n",
    "Aqui nesta função nos detectamos os contornos das bordas já detectadas pela função anterior anteriormente, e nesta função executamos vários passos diferentes.\n",
    "\n",
    "Primeiramente encontramos os contornos utilizando a função homônima da opencv findContours() que nos retornará uma lista de possíveis contornos na imagem. Em seguida nos utilizamos a função approxPolyDP para que posssamos coletar apenas os cotornos que são quadrados, outra filtragem que realizamos é evitar pegar contornos com área ou muito grandes ou muito pequenas, visando eliminar casos que não são desejados.\n",
    "\n",
    "Tendo os quadrados e já eliminando as exceções, principalmente o maior quadrado da imagem, ordenamos os contornos restantes baseados em sua área, e armazenamos apenas os três com maior área. Por fim antes de retornarmos estes contornos temos que realizar um processamento para alterar seu formato, para que possam ser utilizados nas funções futuras.\n",
    "\n",
    "Um ponto importante desta função é que não foi utilizada a função de detecção de quinas recomendada, cornerHarris(), já que atráves dos metódos realizados já foi possível fazer a detecção desejada.\n",
    "\n",
    "#### Fun load_targets()\n",
    "\n",
    "Está função é responsável por carregar a imagem do alvo e aplicar nela as mesmas transformações realizadas na função image_pre_processing(). Após o alvo já processado, o rotacionamos nos 4 possíveis ângulos(0°, 90°, 180° e 270°), e retornamos um array contendo o alvo em cada uma dessas rotações. \n",
    "\n",
    "#### Fun cross_correlation(image_1, image_2)\n",
    "\n",
    "Aqui nós temos a função responsável por calcular a correlação cruzada normalizada entre duas imagens, para fórmula implementada foi utilizada como modelo a fórmula apresentada em sala de aula.\n",
    "\n",
    "#### Fun homograph(image, contours, targets):\n",
    "\n",
    "Aqui nos temos a função que irá realizar a homografia dos contornos encontrados no frame. Primeiramente armazenamos as quinas da imagem do alvo e executamos a função findHomography da opencv, utilizando como parâmetros o contorno encontrado e as quinas do alvo. Posteriormente realizamos a chamada da função warpPerspective para tranformar o contorno no mesmo formato que alvo. Por fim damos um resize na imagem obtida com a última etapa para que ela garantidamente fique com as mesmas dimensões que o alvo.\n",
    "\n",
    "Agora com ambas as imagens podemos realizar o cálculo da correlação cruzada entre a imagem obtida e os alvos em diferentes\n",
    "damos uma valor de 0 a 4, para avaliar a orientação da imagem, sendo de 0 a 3 representadando a orientação/90, e 4 representando que a imagem não é similar a nenhum dos alvos, apenas imagens que tiveram uma correlação cruzada menor do que 0.6 com o alvo em todas as rotoções recebem esse valor. Foi escolhida tal escala pois os índices de 0 a 3 serão utilizados na hora de indicar a orientação da imagem no funçaõ solvepnp().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_loader(num_frames=0):\n",
    "    video = cv2.VideoCapture('entrada.mp4')\n",
    "    images = []\n",
    "    success, image = video.read()\n",
    "    while success:\n",
    "        images.append(image)\n",
    "        success, image = video.read()\n",
    "    \n",
    "    if num_frames == 0:\n",
    "        return images\n",
    "    else:\n",
    "        return images[:num_frames]\n",
    "\n",
    "def image_pre_processing(images, bin_ts = 128):\n",
    "    images_processed = []\n",
    "    for image in images:\n",
    "        image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        th, image_binary = cv2.threshold(image_gray, bin_ts, 255, cv2.THRESH_BINARY)\n",
    "        images_processed.append(image_binary)\n",
    "    \n",
    "    return images_processed\n",
    "\n",
    "def edge_detection(image, low_ts = 100, max_ts = 200, show = False):\n",
    "    edges = cv2.Canny(image, low_ts, max_ts)\n",
    "    \n",
    "    if(show):\n",
    "        plt.figure(figsize=(24,18))\n",
    "        plt.imshow(edges, cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "    return edges\n",
    "\n",
    "def find_contours(edges):\n",
    "    contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    square_contours = []\n",
    "    \n",
    "    for contour in contours:\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, 0.02 * perimeter, True)\n",
    "        if len(approx) == 4 and cv2.contourArea(contour) > 400 and cv2.contourArea(contour) < 20000:\n",
    "            square_contours.append(approx)\n",
    "            \n",
    "    square_contours_selected = sorted(square_contours, key = cv2.contourArea, reverse = True)[:3]\n",
    "    \n",
    "    formated_contours = []\n",
    "    \n",
    "    for element in square_contours_selected:\n",
    "        formated_element = np.array([[element[0][0][0], element[0][0][1]],\n",
    "                                     [element[1][0][0], element[1][0][1]],\n",
    "                                     [element[2][0][0], element[2][0][1]],\n",
    "                                     [element[3][0][0], element[3][0][1]]])\n",
    "        formated_contours.append(formated_element)\n",
    "        \n",
    "    return formated_contours\n",
    "\n",
    "def load_targets():\n",
    "    target = cv2.imread('alvo.jpg')\n",
    "    target = cv2.cvtColor(target, cv2.COLOR_BGR2GRAY)\n",
    "    th, target = cv2.threshold(target, 100, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    target90 = cv2.rotate(target, cv2.ROTATE_90_CLOCKWISE)\n",
    "    target180 = cv2.rotate(target, cv2.ROTATE_180)\n",
    "    target270 = cv2.rotate(target, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    \n",
    "    return [target, target90, target180, target270]\n",
    "\n",
    "def cross_correlation(image_1, image_2): \n",
    "    arr1 = np.subtract(image_1, np.mean(image_1))/np.std(image_1)\n",
    "    arr2 = np.subtract(image_2, np.mean(image_2))/np.std(image_2)\n",
    "    \n",
    "    corr = (arr1 * arr2).sum() / image_1.size\n",
    "\n",
    "    return corr\n",
    "\n",
    "def homograph(image, contours, targets):\n",
    "    target_points = np.array([[0,0], [0, targets[0].shape[1]-1], \n",
    "                              [targets[0].shape[0]-1, targets[0].shape[1]-1], [targets[0].shape[0]-1, 0]])\n",
    "    \n",
    "    homograph, mask = cv2.findHomography(contours, target_points, cv2.RANSAC)\n",
    "    image_out = cv2.warpPerspective(image, homograph, (targets[0].shape[0], targets[0].shape[1]))\n",
    "    \n",
    "    image_out_gray = cv2.cvtColor(image_out, cv2.COLOR_BGR2GRAY)\n",
    "    ret, image_out_binary = cv2.threshold(image_out_gray, 100, 55, cv2.THRESH_BINARY)\n",
    "    \n",
    "    resize_targets = [cv2.resize(targets[0], (image_out_binary.shape[1], image_out_binary.shape[0])), \n",
    "                      cv2.resize(targets[1], (image_out_binary.shape[1], image_out_binary.shape[0])), \n",
    "                      cv2.resize(targets[2], (image_out_binary.shape[1], image_out_binary.shape[0])), \n",
    "                      cv2.resize(targets[3], (image_out_binary.shape[1], image_out_binary.shape[0]))]\n",
    "    \n",
    "    \n",
    "    correlation = 0\n",
    "    orientation = 0\n",
    "    \n",
    "    for index in range(0, len(targets)):\n",
    "        correlation_new = cross_correlation(image_out_binary, targets[index])\n",
    "        if(correlation_new > correlation):\n",
    "            correlation = correlation_new\n",
    "            orientation = index\n",
    "    \n",
    "    if(correlation < 0.6):\n",
    "        orientation = 4\n",
    "\n",
    "    return orientation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedimento de detecção"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui nós executaremos as chamadas das funções implementadas anteriormente, os valores  das variáveis utilizadas apra as chamadas das funções são valores que foram decididos atráves de diferentes testes e os que foram escolhidos apresentaram o resultado mais satisfatório.\n",
    "\n",
    "Foi decidido processar todos os 1100 frames do vídeo, para facilitar a execução das funções da opengl, já que já teremos boa parte dos dados necessários já calculados. Foi pensado em também realizar o pré-processamento do solvePnP, só que só foi notada essa possibilidade tarde demais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:69: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "images = video_loader()\n",
    "targets = load_targets()\n",
    "images_pre_processed = image_pre_processing(images, bin_ts=100)\n",
    "\n",
    "list_contours = []\n",
    "list_orientations = []\n",
    "for frame in range(0, len(images)):\n",
    "    edge = edge_detection(images_pre_processed[frame], low_ts = 100, max_ts = 200)\n",
    "    contours = find_contours(edge)\n",
    "    \n",
    "    orientations = []\n",
    "    for contour in contours:\n",
    "        orientation = homograph(images[frame], contour, targets) \n",
    "        orientations.append(orientation)\n",
    "    \n",
    "    list_contours.append(contours)\n",
    "    list_orientations.append(orientations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exibição dos pikachus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fun Pose(image_points, orientation)\n",
    "\n",
    "Aqui é implementada a função de dectecção de pose, onde primeiramente carregamos os dados obtidos com a calibração\n",
    "da câmera, matriz de parâmetros intrisecos e vetor de distorção, e criamos uma matriz que armazena o ponto de origem da imagem em cada rotação distinta. Posteriormente\n",
    "executamos a função solvePnP da opencv para encontrar a pose da imagem, porém precisamos realizar a chamada da função \n",
    "Rodrigues da opencv para que possamos encontrar a matriz de rotação correta.\n",
    "\n",
    "Com os valores obtidos até o momento podemos realizar a montagem da matriz de parâmetros extrinsecos, porém precisamos \n",
    "fazer a conversão da matriz das coordenadas do opencv para as coordenadas do opengl, poderiamos fazer isso multiplicando por uma matriz de conversão, mas preferi apenas alterar manualmente os sinais da segunda e terceira linhas da matriz de parâmetros extrinsecos.\n",
    "\n",
    "Por fim precisamos transpor essa matriz antes de podermos retorná-la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pose(image_points, orientation):\n",
    "    intrinsic_matrix = np.array([[409.92990, 0.0      , 305.07598],\n",
    "                                 [0.0      , 407.51958, 223.87874],\n",
    "                                 [0.0      , 0.0      , 1.0      ]])\n",
    "    \n",
    "    distortion = np.array([ 0.08372, -0.15473, -0.00711, -0.01103, 0.00000 ])\n",
    "    \n",
    "    object_points = np.array([[[-1.0, -1.0, 0.0], [ 1.0, -1.0, 0.0], [ 1.0,  1.0, 0.0], [-1.0,  1.0, 0.0]],\n",
    "                              [[ 1.0, -1.0, 0.0], [ 1.0,  1.0, 0.0], [-1.0,  1.0, 0.0], [-1.0, -1.0, 0.0]],\n",
    "                              [[ 1.0,  1.0, 0.0], [-1.0,  1.0, 0.0], [-1.0, -1.0, 0.0], [ 1.0, -1.0, 0.0]],\n",
    "                              [[-1.0,  1.0, 0.0], [-1.0, -1.0, 0.0], [ 1.0, -1.0, 0.0], [ 1.0,  1.0, 0.0]]])\n",
    "    \n",
    "    success, rotation_vector, translation_vector = cv2.solvePnP(object_points[orientation], np.float32(image_points), \n",
    "                                            intrinsic_matrix, distortion, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "    \n",
    "    rotation_matrix = cv2.Rodrigues(rotation_vector)[0]\n",
    "    \n",
    "    extrinsic_matrix = np.array([[ rotation_matrix[0][0],  rotation_matrix[0][1],  rotation_matrix[0][2],  translation_vector[0]],\n",
    "                                 [-rotation_matrix[1][0], -rotation_matrix[1][1], -rotation_matrix[1][2], -translation_vector[1]],\n",
    "                                 [-rotation_matrix[2][0], -rotation_matrix[2][1], -rotation_matrix[2][2], -translation_vector[2]],\n",
    "                                 [0.0                   , 0.0                   , 0.0                   ,  1.0                  ]])\n",
    "    \n",
    "    return extrinsic_matrix.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fun updateFrame()\n",
    "\n",
    "Esta função é reponsável por atualizar o índice do frame que será utilizado na proxima cena, ela também incrementa o ângulo de rotação do pikachu, para faze-la ficar mais percepitivel o aumentamos de 3 em 3.\n",
    "\n",
    "#### Fun drawBackground()\n",
    "\n",
    "Esta função é responsável por pegar uma imagem e coloca-la como textura em um quadrado que ocupe a janela toda.\n",
    "\n",
    "Primeiramente nos habilitamos o uso de texturas, já que será necessário e também desativamos a profundidade da janela, em seguida nos copiamos o frame que queremos utilizar como background, e realizamos um flip nela, já que caso contrário ela ficaria de cabeça para baixa na janela. Em seguida carregamos esta imagem como uma textura que será aplicada quando desenharmos o quadrado. Com a imagem como textura podemos desenhar o quadrado, primeiramente configuramos a matriz de projeção e de modelagem, para que ele fique correto, em seguida o desenhamos em si. por fim com o quadrado já com a textura desenhado habilitamos a profundidade da janela.\n",
    "\n",
    "#### drawSquare()\n",
    "\n",
    "Esta função é responsável por desenhar um quadrado onde o alvo foi detectado.\n",
    "\n",
    "Primeiramente desabilitamos o uso de textura para que possamos desenhar o quadrado sem afetar nada, em seguida definimos uma grossura de linha que o faça ficar bem destacado quando na imagem, por teste foi escolhido uma grossura de 2.5, em seguida verificamos se os quadrados detectados são realmente alvos, se não forem (valor de orirentação igual a 4) iremos para o proximo quadrado detectado, caso tenhamos detectado um quadrado, nos utilizamos o glBegin(GL_LINE_LOOP) para desenhar um quadrado, a cor selecionada foi a mesma mostrada em sala, o verde. \n",
    "\n",
    "Um ponto interessante é que com invertemos a imagem, não podemos utilizar o Y encontrado, temos que fazer 480 - Y, para conseguirmos o valor de Y correto na hora de desenhar as linhas. Antes de terminarmos a função reativamos as texturas e retornamos o valor e a cor das linhas ao normal.\n",
    "\n",
    "#### Fun initOpenGL(dimensions)\n",
    "\n",
    "Esta função é responsável por construir a matriz de projeção correta, não foram feitas muitas alterações em relação a função que foi disponibilizada, somente adicionamos os parâmetros obtidos com a calibração de câmera, e as funções de fovy e aspect seguem as mesmas mostradas em sala de aula\n",
    "\n",
    "#### Fun object3D(obj)\n",
    "\n",
    "Esta função é responsável por desenhar todos os objetos que dependem do posicionamento da câmera, ou seja o cubo e o pikachu.\n",
    "\n",
    "Primeiramente nós fazemos a checagem se a orientação não é 4, se for nos passamos para o próximo contorno, caso contrário nos iniciamos o processo de desenho das figuras. O primeiro passo é obter a posição da câmera, que é adquirida ao chamarmos a função Pose(image_points, orientation), passando como parâmetro o contorno e a orientação do mesmo. Ems seguida desabilitamos a profundidade e configuramos a posição da câmera, inicialmente alterando a matriz de projeão,em seguida carregando a perspectiva da câmera, e por fim antes de iniciarmos os desenhos, nós carrregamos a matriz de modelagem e a matriz contendo a pose da câmera.\n",
    "\n",
    "Com tudo configurado podemos começar a desenhar as figuras, mas antes desabilitamos as texturas, depois utilizamos a função glutWireCube(2.0) para desenhar um cubo de tamanho 2x2x2, note que antes e depois de desenha-lo executamos um translate no cubo, isso serve para deixá-lo um pouco mais alinhado com o alvo em si. Em seguida ainda no cubo desenhamos uma linha que indica a orientação do cubo, está linha para ficar mais perceptivel é mais grossa que o cubo. Por fim desenhamos os pikachus na tela, so que antes disso habilitamos as texturas e profundidade, e aplicamos uma rotação ao pikachu. \n",
    "\n",
    "Com relação a rotação foi definido que caso o ponto inicial do contorno fosse acima de um limite em X e Y ele giraria em sentido horario, e caso contrário ele rodaria no sentido anti-horário, isto foi feito pois era de conhecido que apenas o alvo 2 deveria girar no sentido horário e ele sempre ficava na posição superior da janela.\n",
    "\n",
    "#### Fun displayCallback()\n",
    "\n",
    "Está função irá orientar o que iremos mostrar na tela.\n",
    " \n",
    "Primeiramente nós carregamos a matriz de modelagem e limpamos o buffer de cor, assim limpando a imagem por completo. Em seguida chamamos a função drawBackground() para adicionar o frame atual como background, em seguida no chamamos a função drawSquare() para desenhar as localizações dos alvos, em seguida carregamos o modelo do pikachu e chamamos a função object3d(obj), para desenhar o cubo a orientação do cubo e o pikachu rotacionado.\n",
    "\n",
    "Terminado tudo a ser desenhado damos um swap no buffer e chamamos a função updateFrame(), para atualizar o frame da proxima iteração do callback e aumentar o angulo de rotação.\n",
    "\n",
    "#### Fun idleCallback()\n",
    "\n",
    "Está é a função de idle, que não foi alterado em comparação com a fornecida\n",
    "\n",
    "#### Main\n",
    "\n",
    "Será o responsável por iniciar a janela do opengl, em comparação com o fornecido foi alterada apenas o nome da janela para \"Realidade Aumentada - Pikachu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "frame = 0\n",
    "rotation = 0\n",
    "\n",
    "def updateFrame():\n",
    "    global frame\n",
    "    global rotation\n",
    "    \n",
    "    rotation += 3\n",
    "    frame += 1\n",
    "    \n",
    "def drawBackground():\n",
    "    global frame\n",
    "    global images\n",
    "    \n",
    "    glEnable(GL_TEXTURE_2D)\n",
    "    glDisable(GL_DEPTH_TEST)\n",
    "    glDepthMask(GL_FALSE)\n",
    "    \n",
    "    image_background = images[frame].copy()\n",
    "    image_background = cv2.cvtColor(image_background, cv2.COLOR_BGR2RGB)\n",
    "    image_background = cv2.flip(image_background, 0)\n",
    "    \n",
    "    height, width, _ = image_background.shape\n",
    "    \n",
    "    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, image_background)\n",
    "    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST)\n",
    "    \n",
    "    glMatrixMode(GL_PROJECTION)\n",
    "    glLoadIdentity()\n",
    "    gluOrtho2D(0, width, 0, height)\n",
    "\n",
    "    glMatrixMode(GL_MODELVIEW)\n",
    "    glLoadIdentity()\n",
    "\n",
    "    glBegin(GL_QUADS)\n",
    "    glTexCoord2f(0.0, 0.0)\n",
    "    glVertex2f(0.0, 0.0)\n",
    "    glTexCoord2f(1.0, 0.0)\n",
    "    glVertex2f(width, 0.0)\n",
    "    glTexCoord2f(1.0, 1.0)\n",
    "    glVertex2f(width, height)\n",
    "    glTexCoord2f(0.0, 1.0)\n",
    "    glVertex2f(0.0, height)\n",
    "    glEnd()\n",
    "    \n",
    "    glEnable(GL_DEPTH_TEST)\n",
    "    glDepthMask(GL_TRUE)\n",
    "    \n",
    "def drawSquare():\n",
    "    global frame\n",
    "    global list_contours\n",
    "    global list_orientations\n",
    "    \n",
    "    glDisable(GL_TEXTURE_2D)\n",
    "    glLineWidth(2.5)\n",
    "    \n",
    "    index = 0\n",
    "    for contour in list_contours[frame]:\n",
    "        if list_orientations[frame][index] == 4:\n",
    "            continue\n",
    "        glBegin(GL_LINE_LOOP);\n",
    "        glColor3f(0.0, 1.0, 0.0);\n",
    "        glVertex2f(contour[0][0], 480 - contour[0][1])\n",
    "        glVertex2f(contour[1][0], 480 - contour[1][1])\n",
    "        glVertex2f(contour[2][0], 480 - contour[2][1])\n",
    "        glVertex2f(contour[3][0], 480 - contour[3][1])\n",
    "        glEnd()\n",
    "        index+=1\n",
    "    \n",
    "    glColor3fv((1,1,1))\n",
    "    glLineWidth(1.0)\n",
    "    glEnable(GL_TEXTURE_2D)\n",
    "        \n",
    "def initOpenGL(dimensions):\n",
    "    (width, height) = dimensions\n",
    "    \n",
    "    glClearColor(0.0, 0.0, 0.0, 0.0)\n",
    "    glClearDepth(1.0)\n",
    "\n",
    "    glEnable(GL_DEPTH_TEST)\n",
    "\n",
    "    glMatrixMode(GL_PROJECTION)\n",
    "    glLoadIdentity()\n",
    " \n",
    "    fovy = 2*np.arctan(0.5*480/407.51958)*180/np.pi;\n",
    "    aspect = (640*407.51958)/(480*409.92990)\n",
    "    gluPerspective(fovy, aspect, 0.1, 100.0)\n",
    "        \n",
    "def object3D(obj):\n",
    "    global frame\n",
    "    global rotation\n",
    "    global list_contours\n",
    "    global list_orientations\n",
    "    \n",
    "    for index in range(len(list_contours[frame])):\n",
    "        if list_orientations[frame][index] == 4:\n",
    "            continue\n",
    "        \n",
    "        pose = Pose(list_contours[frame][index], list_orientations[frame][index])\n",
    "        \n",
    "        glDisable(GL_DEPTH_TEST)\n",
    "        \n",
    "        glMatrixMode(GL_PROJECTION)\n",
    "        glLoadIdentity()\n",
    "        \n",
    "        fovy = 2*np.arctan(0.5*480/407.51958)*180/np.pi;\n",
    "        aspect = (640*407.51958)/(480*409.92990)\n",
    "        gluPerspective(fovy, aspect, 0.1, 100.0)\n",
    "        #gluOrtho2D(0, 640, 0, 480)\n",
    "\n",
    "        glMatrixMode(GL_MODELVIEW)\n",
    "        glLoadIdentity()\n",
    "        \n",
    "        glLoadMatrixf(pose)\n",
    "        \n",
    "        glDisable(GL_TEXTURE_2D)\n",
    "        \n",
    "        glTranslate(0, 0, 1)\n",
    "        glutWireCube(2.0)\n",
    "        glTranslate(0, 0, -1)\n",
    "        \n",
    "        glLineWidth(3)\n",
    "        glBegin(GL_LINES);\n",
    "        glVertex2f(0, 0)\n",
    "        glVertex2f(-2, 0)\n",
    "        glEnd()\n",
    "        glLineWidth(1)\n",
    "        \n",
    "        glEnable(GL_TEXTURE_2D)\n",
    "        glEnable(GL_DEPTH_TEST)\n",
    "        \n",
    "        if list_contours[frame][index][0][0] > 320 and 480 - list_contours[frame][index][0][1] > 240:\n",
    "            glRotate(-rotation, 0,0,1)\n",
    "        else:\n",
    "            glRotate(rotation, 0,0,1)\n",
    "        \n",
    "        glCallList(obj.gl_list)\n",
    "        \n",
    "    \n",
    "def displayCallback():\n",
    "    glMatrixMode(GL_MODELVIEW)\n",
    "    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)\n",
    "    glLoadIdentity()\n",
    "    \n",
    "    drawBackground()\n",
    "    \n",
    "    drawSquare()\n",
    "    \n",
    "    obj = OBJ(\"Pikachu.obj\", swapyz=True)\n",
    "    \n",
    "    object3D(obj) \n",
    "        \n",
    "    glutSwapBuffers()\n",
    "    updateFrame()\n",
    "    \n",
    "\n",
    "def idleCallback():\n",
    "    glutPostRedisplay()\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    dimensions = (640, 480)\n",
    "    glutInit()\n",
    "    glutInitDisplayMode(GLUT_RGBA | GLUT_DOUBLE)\n",
    "    glutSetOption(GLUT_ACTION_ON_WINDOW_CLOSE, GLUT_ACTION_CONTINUE_EXECUTION)\n",
    "    glutInitWindowSize(*dimensions)\n",
    "    window = glutCreateWindow(b'Realidade Aumentada - Pikachu')\n",
    "    \n",
    "    initOpenGL(dimensions)\n",
    "    \n",
    "    glutDisplayFunc(displayCallback)\n",
    "    glutIdleFunc(idleCallback)\n",
    "    \n",
    "    glutMainLoop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fontes utilizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
